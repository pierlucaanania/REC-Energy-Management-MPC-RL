# "Reinforcement Learning for Optimal Energy Management in Renewable Energy Communities" (_example of title, to be defined_)
<p align="center">
    <img src="https://ars.els-cdn.com/content/image/1-s2.0-S1367578820300079-gr3.jpg" width="500" height="300" />
    <br>    
    <em>  Potential Applications of RL to REC Energy Management. </em>
</p>


## Description

This GitHub repository hosts the code and resources for my Master's thesis in Mechanical Engineering, focusing on the application of Reinforcement Learning techniques to the Energy Management of a Renewable Energy Community. The goal of this research is to develop efficient strategies for optimizing the energy production, consumption and distribution within a local community powered by renewable sources. (//ToBeUpdated with more details of Ponza)

## Table of Contents

- [Introduction](#introduction)
- [Dependencies](#dependencies)
- [Structure](#structure)
- [Usage](#usage)
- [Results](#results)
- [Contributions](#contributions)
- [License](#license)

## Introduction
_example_: (add a brief description of the project, what it does, and how it works)

// In recent times, the transition to sustainable and renewable energy sources has become paramount. This project aims to address the challenges of managing energy within a localized community that primarily relies on renewable energy generation, such as solar panels, wind turbines, and more. The application of reinforcement learning techniques to energy management problems offers the potential to optimize energy consumption, storage, and distribution in a dynamic and adaptable manner.

## Dependencies

- Python 3.7+
- TensorFlow
- OpenAI Gym
- Other necessary libraries listed in `requirements.txt`
- _//ToBeUpdated_
## Structure  

*//ToBeUpdated* --> Only an idea of the structure of the repository
```
ðŸ“‚ MScThesis_RL-REC

â”‚   ðŸ“„ README.md                     # Introduction document
â”‚   ðŸ“„ LICENSE                       # License information
â”‚   ðŸ“„ .gitignore                    # Gitignore configuration file
â”‚
â””â”€â”€â”€ ðŸ“‚ Learning Material         # Papers, books, and other learning material
â”‚   â”‚   ðŸ“„ papers.md                 # List of relevant scientific papers
â”‚   â”‚   ðŸ“„ books.md                  # List of consulted books
â”‚   â”‚   ðŸ“„ðŸ“„ papers
â”‚
â”‚
â””â”€â”€â”€ ðŸ“‚ draft                        # Draft code
â”‚
â””â”€â”€â”€ ðŸ“‚ src                          # Source code
â”‚   â”‚
â”‚   â””â”€â”€â”€ ðŸ“‚ data                       # Input data
â”‚       â”‚   ðŸ“„ consumption.csv         # Energy consumption data
â”‚       â”‚   ðŸ“„ production.csv          # Energy production data
â”‚       â”‚   ...
â”‚   â”‚
â”‚   â””â”€â”€â”€ ðŸ“‚ models                     # Reinforcement learning models
â”‚       â”‚   ðŸ“„ dqn_model.py            # DQN model implementation
â”‚       â”‚   ðŸ“„ actor_critic_model.py   # Actor-Critic model implementation
â”‚       â”‚   ...
â”‚   â”‚
â”‚   â””â”€â”€â”€ ðŸ“‚ utils                      # Utility and helper functions
â”‚       â”‚   ðŸ“„ data_preprocessing.py   # Data preprocessing
â”‚       â”‚   ðŸ“„ energy_calculations.py  # Energy calculations
â”‚       â”‚   ...
â”‚
â””â”€â”€â”€ ðŸ“‚ docs                           # Documentation
â”‚   â”‚   ðŸ“„ thesis.pdf                  # Final version of the thesis in PDF
â”‚   â”‚   ðŸ“„ presentation.pptx           # Presentation for thesis defense
â”‚   â”‚   ...
â”‚
â””â”€â”€â”€ ðŸ“‚ experiments                    # Experimental results // Application
â”‚   â”‚
â”‚   â””â”€â”€â”€ ðŸ“‚ experiment_1               # Experiment 1: Configuration parameters X
â”‚   â”‚   â”‚   ðŸ“„ results.txt             # Quantitative results of experiment 1
â”‚   â”‚   â”‚   ðŸ“„ analysis.md             # Qualitative analysis of results
â”‚   â”‚
â”‚   â””â”€â”€â”€ ðŸ“‚ experiment_2               # Experiment 2: Configuration parameters Y
â”‚       â”‚   ...
â”‚
â”‚
â””â”€â”€â”€ ðŸ“‚ references                     # Documents and references
â”‚   â”‚   ðŸ“„ papers.md                   # List of relevant scientific papers
â”‚   â”‚   ðŸ“„ books.md                    # List of consulted books
â”‚   â”‚   ...
â”‚
â””â”€â”€â”€ ðŸ“‚ presentation                   # Presentation materials
â”‚   â”‚   ðŸ“„ slide1.pptx                 # Slides
â”‚   â”‚   ðŸ“„ slide2.pptx                 # Slides
â”‚   â”‚   ...
â”‚
â””â”€â”€â”€ ðŸ“‚ screenshots                    # Example screenshots or visualizations
â”‚   â”‚   ðŸ“„ screenshot_1.png            # Example data visualization
â”‚   â”‚   ðŸ“„ screenshot_2.png            # Example results visualization
â”‚   â”‚   ...

```


## Usage
**A/N: Private Repository, not available for public use. This section will be updated with instructions on how to use the code once the thesis is completed.**

1. Clone the repository:

```bash
git clone https://github.com/pierlucaanania/MScThesis_RL-REC.git
cd MScThesis_RL-REC
```
2. Set up the environment: _#ToBeUpdated_

```bash
python3 -m venv venv
source venv/bin/activate
```
3. Install the dependencies

```bash
pip install -r requirements.txt
```
4. Run the code
    
```bash
#add running script if exists
``` 

## Results
_example_:

// The results of applying reinforcement learning techniques to the renewable energy community energy management problem will be documented in the 'results' directory. This section will include data visualizations, analysis, and comparisons of different algorithms.

## Contributions
**A/N: Private Repository, not available for public use. This section will be updated with instructions on how to use the code once the thesis is completed.**

Contributions to this project are welcome! If you have suggestions, bug fixes, or improvements, please feel free to open an issue or submit a pull request. Let's collaborate to advance the understanding of efficient energy management using reinforcement learning.

## License and Contact
This project is under [MIT License](https://choosealicense.com/licenses/mit/)

Author: *Pier Luca Anania*

Contact: 
1. [anania.1653220@studenti.uniroma1.it](mailto:anania.1653220@studenti.uniroma1.it)
2. [p.l.anania@gmail.com](mailto:p.l.anania@gmail.com)

University: [Sapienza University of Rome](https://www.uniroma1.it/it/pagina-strutturale/home)

Department: [DIMA Mechanical and Aerospace Engineering](https://www.dima.uniroma1.it/en)

